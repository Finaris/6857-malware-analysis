import pandas as pd
import numpy as np
import json
from pandas.io.json import json_normalize
import os
import csv
import ast
import matplotlib.pyplot as plt
import datetime

class MalwareAnalyzer(object):
    CC_DICT = ast.literal_eval(open('processed/country_codes.txt', 'r').read())
    CC_DICT_REV = {v: k for k, v in CC_DICT.items()}
    def __init__(self, inp = "raw_output/json_data", merged = False):
        """Init functions expects a directory of jsons."""
        self.inp = inp
        if not merged:
            self.df = self.get_df_from_dir()
            self.df_normalizer()
        else:
            self.df = pd.read_csv(inp)
        self.df.drop_duplicates(inplace = True)
        # convert datetime related columns to datetime
        for col in ["date", "year", "year-month", "year-month-day"]:
            self.df[col] = pd.to_datetime(self.df[col],infer_datetime_format=True)

    def get_df_from_dir(self):
        """
        From a directory of json files, reads and returns
        a combined dataframe.
        """
        df = pd.DataFrame()
        for f in os.listdir(self.inp):
            if f.endswith(".json"):
                index = f.find("Scraper")
                source = f[:index]
                # merging files from the same source that had to
                # be split due to storage limits
                if source[-1] in ["1", "2"]:
                    source = source[:-1]
                path = self.inp + "/" + f
                currdf = pd.read_json(path, orient = 'records')
                currdf["scraper"] = source
                df = pd.concat([df, currdf])
        return df

    def df_normalizer(self):
        """
        Helper function for normalizing the fields of the stored
        dataframe.
        """
        # turning to all upper case (can use lower and then .title() later if desired)
        self.df["origin_country"] = self.df["origin_country"].apply(lambda x: str(x).upper())
        # temporary columns for holding the converted version of cc and origin_country
        self.df["updated_country"] = self.df["cc"].apply(lambda x: self.CC_DICT[x] if not pd.isna(x) else x)
        self.df["updated_cc"] = self.df["origin_country"].apply(lambda x: self.CC_DICT_REV[x] if x!='NAN' else np.nan)
        # combine if not present
        self.df["origin_country"] = self.df[["origin_country", "updated_country"]].apply(lambda x: x[1] if x[0] == 'NAN' else x[0], axis=1)
        self.df["cc"] = self.df[["cc", "updated_cc"]].apply(lambda x: x[1] if pd.isna(x[0]) else x[0], axis=1)
        # drop the temporary columns
        self.df.drop(["updated_country", "updated_cc"], axis = 1, inplace = True)
        # standardizing the categories
        self.df["category"] = self.df["category"].apply(lambda x: "general malware" if x == "general_malware" else x)
        # splitting into specific date bits for analysis
        self.df["year"] = self.df["date"].apply(lambda x: str(x).split()[0].split("-")[0] if not pd.isna(x) else x)
        self.df["year-month"] = self.df["date"].apply(lambda x: str(x).split()[0][:-3] if not pd.isna(x) else x)
        self.df["year-month-day"] = self.df["date"].apply(lambda x: str(x).split()[0] if not pd.isna(x) else x)

    @staticmethod
    def get_country_codes_from_url(x):
        pass

    def get_description(self, out_dir):
        """
        Gets a basic description of the combined dataframe.
        Currently, reads the summary statistics of the numerical
        fields and the unique values of the non-numerical fields
        to outdir.
        """
        describedf = self.df.describe(include=[np.number])
        describedf.to_csv(out_dir + "/numerical.csv")
        unique = {}
        other_columns = self.df.select_dtypes(exclude=[np.number]).columns
        for col in other_columns:
            try:
                unique_vals = sorted(list(self.df[col].unique())[:100])
            except:
                unique_vals = list(self.df[col].unique())[:100]
            unique[col] = unique_vals
        with open(out_dir + "/other.csv", "w") as csv_file:
            writer = csv.writer(csv_file)
            for key, val in unique.items():
                writer.writerow([key, val])
        print("Counts")
        print(self.df.count())

    def get_n_most_frequent(self, n, out_dir):
        """Gets the n most frequent values for each column of the dataframe.
        Args:
            n (int): the number of top most frequent values to look at.
            out_dir (str): the path to write the frequency description
                file to.
        Returns:
            None, but writes the aforementioned to [out_dir]/frequent.csv
        """
        col_dict = {}
        for col in self.df.columns:
            countdf = self.df[col].value_counts().head(n)
            col_dict[col] = {"values": {k: v for k, v in enumerate(countdf.index.tolist())},
                             "counts": {k: v for k, v in enumerate(countdf.tolist())}}
        outdf = pd.concat({k: pd.DataFrame(v).T for k, v in col_dict.items()}, axis=0)
        outdf.to_csv(out_dir + "/frequent.csv")

    def plot_ym_graph(self, bucket_size, fig_dir = None):
        """
        Plots a graph of counts per year-month bucket.
        Args:
            bucket_size (int) : number of months per bucket.
            fig_dir (string, optional): figures directory to write plot out to
        Returns:
            None, but shows plot and writes to fig_dir
        """
        # buckets, with naming convention on the left of bucket
        bucketdf = self.df.resample(str(bucket_size) + "M", on="year-month")["date"].count()
        # convert datetime back into readable string
        bucketdf.index = bucketdf.index.strftime("%m-%y")
        # plot
        plot = bucketdf.plot(kind="bar", width=1,
                             title="Month-Year Counts with a bucket size of %d" % bucket_size,
                             colormap = "Purples_r")
        plot.set_xlabel("MM-YY")
        plot.set_ylabel("Counts")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/year_month_%d.png" % (fig_dir, bucket_size))

    def plot_counts_graph(self, column, n, fig_dir = None):
        """
        Plots a graph of counts for a categorical column.
        Args:
            column (string) : categorical column name.
            n (int): the number of top most frequent values to look at.
            fig_dir (string, optional): figures directory to write plot out to.
        Returns:
            None, but shows plot and writes to fig_dir
        """
        plot = self.df[column].value_counts().head(n).plot(kind="bar",
                                                           colormap = "Reds_r",
                                                           title="Top %d %s Counts" % (n, column))
        plot.set_xlabel("%s values" % column)
        plot.set_ylabel("Counts")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/%s_counts.png" % (fig_dir, column))

    def plot_categories(self, fig_dir = None):
        """Plots a pie chart of the different malware categories"""
        plot = self.df["category"].value_counts().plot.pie(title = "Malware Categories",
                                                           labels = None,
                                                           legend = True,
                                                           startangle=90, shadow=False,
                                                           fontsize=10, colormap = "Set3")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/categories.png" % fig_dir)

    def get_category_over_time(self, category, fig_dir = None):
        """Plots category counts over time."""
        cat_df = self.df[self.df["category"] == category]
        counts_df = cat_df["year-month"].value_counts()
        counts_df.sort_index(inplace=True)
        counts_df.index = counts_df.index.strftime("%m-%y")
        counts_df.dropna(inplace = True)
        counts_df = counts_df.iloc[5:]
        plot = counts_df.plot(kind = "bar", colormap = "Reds_r",
                              title="%s over time" % category)
        plot.set_xticklabels(counts_df.index)
        plot.set_xlabel("MM-YY")
        plot.set_ylabel("Counts")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/%s_over_time.png" % (fig_dir, category))

    def get_hashes(self, out_dir):
        """
        Get those entries that have either md5 or sha256
        hashes. Returns those columns, along with the url.
        """
        hashdf = self.df.dropna(subset=["md5", "sha256"], how='all')
        hashdf = hashdf[["md5", "sha256", "url"]]
        hashdf.to_csv(out_dir + "/hashes.csv")

    def get_df(self):
        """Returns a copy of the stored dataframe."""
        return self.df.copy()

    def print_df(self, outfile):
        """Writes the stored dataframe to outfile."""
        self.df.to_csv(outfile, index = False)



if __name__ == "__main__":
    # first run this
    # ma = MalwareAnalyzer("raw_output/json_data")
    # ma.print_df("processed/data_all.csv")
    # afterwards use this, comment two lines above out
    ma = MalwareAnalyzer("processed/data_all.csv", True)
    ma.get_hashes("processed/descriptions")
    ma.get_category_over_time("ransomware", "figures")
    # ma.get_description("processed/descriptions")
    # ma.get_n_most_frequent(5, "processed/descriptions")
    # ma.plot_ym_graph(3, "figures")
    # ma.plot_categories("figures")
    # ma.plot_counts_graph("origin_country", 10, "figures")
    

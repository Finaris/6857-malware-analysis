import pandas as pd
import numpy as np
import json
from pandas.io.json import json_normalize
import os
import csv
import matplotlib.pyplot as plt
import ast

class ResponseAnalyzer(object):
    KEY = ast.literal_eval(open('processed/keywords.txt', 'r').read())
    def __init__(self, inp, merged = False):
        """
        Initializes an analyzer for VirusTotal response csv,
        as outputted by csv_read.py.
        Args:
            inp (str): either a directory containing raw csvs, or a
                a single cleaned, merged csv.
            merged (bool): if inp is a directory, set merged to False.
                Else, set to true.
        """
        # NOTE: since the unrolling is slow, we would suggest running once,
        # printing to a csv, and loading it using merged = True
        self.input = inp
        if not merged:
            self.df = pd.DataFrame()
            for f in os.listdir(self.input):
                if f.endswith(".csv"):
                    path = self.input + "/" + f
                    currdf = pd.read_csv(path)
                    response_df = self.unroll_response_col(currdf)
                    currdf = currdf.merge(response_df, on ="i")
                    self.df = pd.concat([self.df, currdf])
            self.df.drop(["response"], axis = 1, inplace = True)
            self.df["md5"] = self.df[["md5_x", "md5_y"]].apply(lambda x: x[1] if pd.isnull(x[0]) else x[0], axis=1)
            self.df["sha256"] = self.df[["sha256_x", "sha256_y"]].apply(lambda x: x[1] if pd.isnull(x[0]) else x[0], axis=1)
            self.df.drop(["md5_x", "md5_y", "sha256_x", "sha256_y"], axis = 1, inplace = True)
            self.process_date_time()
        else:
            self.df = pd.read_csv(self.input)
        #self.get_date_consensus()

    def process_date_time(self):
        """Helper function for processing the date-time columns and adding year and year-month fields."""
        for col in self.df.columns:
            if "update" in col:
                header = '.'.join(col.split(".")[:-1])
                self.df[header + ".year"] = self.df[col].apply(lambda x: np.datetime64(str(x)[:4]) if not pd.isnull(x) else x)
                self.df[header + ".year-month"] = self.df[col].apply(lambda x: np.datetime64(str(x)[:4] + "-" + str(x)[4:6]) if not pd.isnull(x) else x)
                self.df[col] = self.df[col].apply(lambda x: np.datetime64(str(x)[:4] + "-" + str(x)[4:6] + "-" + str(x)[6:8]) if not pd.isnull(x) else x)
                
    def unroll_response_col(self, df):
        """Unrolls response column (with a json value) into individual columns."""
        outdf = pd.DataFrame()
        for index, row in df.iterrows():
            r_dict = ast.literal_eval(row["response"])
            currdf = json_normalize([r_dict])
            currdf["i"] = row["i"]
            outdf = pd.concat([outdf, currdf])
        return outdf

    def get_keywords_df(self):
        """Uses the KEY dictionary to standardize the results into
        keywords using a >3 consensus."""
        result_columns = [col for col in self.df.columns if "result" in col]
        # TODO: to clean
        phrases = []
        for _, row in self.df.iterrows():
            keywords = {}
            for key, val in self.KEY.items():
                count = 0
                for col in result_columns:
                    if any(word in str(row[col]) for word in val):
                        count += 1
                if count >= 3:
                    keywords[key] = 1
            phrases.append(" ".join(keywords.keys()) if len(keywords) > 0 else None)
        self.df["result"] = np.array(phrases)
        self.df.drop(result_columns, axis = 1, inplace = True)
                        

    def get_date_consensus(self):
        """Standardizes the year and year month by choosing
        the majority values."""
        year_columns = [col for col in self.df.columns if "year" in col and "year-month" not in col]
        year_month_columns = [col for col in self.df.columns if "year-month" in col]
        years = []
        year_months = []
        for _, row in self.df.iterrows():
            year_totals = {}
            ym_totals = {}
            for col in year_columns:
                if not pd.isnull(row[col]):
                    year_totals[row[col]] = year_totals.get(row[col], 0) + 1
            for col in year_month_columns:
                if not pd.isnull(row[col]):
                    ym_totals[row[col]] = ym_totals.get(row[col], 0) + 1
            years.append(max(year_totals, key=year_totals.get) if len(year_totals) > 0 else None)
            year_months.append(max(ym_totals, key=ym_totals.get) if len(ym_totals) > 0 else None)
        self.df["year"] = np.array(years)
        self.df["year-month"] = np.array(year_months)
        self.df.drop(year_columns + year_month_columns, axis = 1, inplace = True)

    def get_description(self, out_dir):
        """
        Gets a basic description of the combined dataframe.
        Currently, reads the summary statistics of the numerical
        fields and the unique values of the non-numerical fields
        to outdir.
        """
        describedf = self.df.describe(include=[np.number])
        describedf.to_csv(out_dir + "/hash_numerical.csv")
        unique = {}
        other_columns = self.df.select_dtypes(exclude=[np.number]).columns
        for col in other_columns:
            try:
                unique_vals = sorted(list(self.df[col].unique())[:100])
            except:
                unique_vals = list(self.df[col].unique())[:100]
            unique[col] = unique_vals
        with open(out_dir + "/hash_other.csv", "w") as csv_file:
            writer = csv.writer(csv_file)
            for key, val in unique.items():
                writer.writerow([key, val])
        counts_dict = self.df.count().to_dict()
        with open(out_dir + "/hash_counts.csv", 'w') as f:
            for key in counts_dict.keys():
                f.write("%s,%s\n"%(key,counts_dict[key]))

    def get_df(self):
        return self.df.copy()

    def print_csv(self, outfile):
        """Prints the dataframe to outfile."""
        self.df.to_csv(outfile, index = False)

    def analyze_results(self, out_dir):
        """
        Function for getting the percentages
        for each keyword within result.
        The resulting file is printed out to out_dir.
        """
        if "result" not in self.df.columns:
            raise ValueError
        denominator = len(self.df["result"].dropna().index)
        percents = {}
        for key in self.KEY:
            filtered = self.df[self.df["result"].str.contains(key, na = False)]
            percents[key] = len(filtered.index)/denominator
        with open(out_dir + "/result_percents.csv", 'w') as f:
            for key in percents.keys():
                f.write("%s,%s\n"%(key, percents[key]))

    def get_duplicates_analysis(self, outfile):
        """
        Gets number of duplicates and reads all unique hashes
        into new csv.
        """
        duplicates = len(self.df.index) - len(self.df.drop_duplicates(["md5", "sha256"]).index)
        self.df.drop_duplicates(["md5", "sha256"]).to_csv(outfile, index = False)
        print("Duplicates", duplicates)

    def get_real_malware_analysis(self):
        not_real_malware = len(self.df.loc[self.df["positives"] == 0].index)
        print("Falsely Detected Malware", not_real_malware)
        print("Percentage", not_real_malware/float(len(self.df.index)))

    def plot_year_graph(self, fig_dir = None):
        """
        Plots a graph of counts per year.
        Args:
            fig_dir (string, optional): figures directory to write plot out to
        Returns:
            None, but shows plot and writes to fig_dir
        """
        
        # buckets, with naming convention on the left of bucket
        series = self.df.dropna(subset = ["year"])["year"]
        series = series.apply(lambda x: str(x).split("-")[0])
        bucketdf = series.value_counts() #.resample(str(bucket_size) + "M", on="year-month")["i"].count()
        bucketdf.sort_index(inplace=True)
        # plot
        plot = bucketdf.plot(kind="bar",
                             title="Year Counts",
                             colormap = "Purples_r")
        plot.set_xlabel("Year")
        plot.set_ylabel("Counts")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/year_hash.png" % (fig_dir))

    def get_result_over_time(self, keyword, fig_dir = None):
        """Plots keyword proportion over time."""
        overall = self.df.dropna(subset = ["year-month"])["year-month"].apply(lambda x: str(x)[2:-3])
        overall = overall.value_counts()
        cat_df = self.df.dropna(subset = ["year-month"])[self.df["result"].str.contains(keyword, na = False)]
        series = cat_df["year-month"].apply(lambda x: str(x)[2:-3])
        counts_df = series.value_counts().div(overall, fill_value = 0)
        counts_df.sort_index(inplace=True)
        counts_df.dropna(inplace = True)
        if counts_df.empty:
            return
        plot = counts_df.plot(kind = "bar", colormap = "Reds_r",
                              title="%s over time" % keyword)
        plot.set_xticklabels(counts_df.index)
        plot.set_xlabel("YY-MM")
        plot.set_ylabel("Proportion")
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/%s_over_time.png" % (fig_dir, keyword))

    def plot_keyword_counts(self, fig_dir, proportion = True):
        """Plots keywords counts or proportions (if proportion = True) in a bar graph"""
        denominator = len(self.df["result"].dropna().index)
        counts = []
        for keyword in self.KEY:
            current_count = len(self.df[self.df["result"].str.contains(keyword, na = False)].index)
            if proportion:
                counts.append((keyword, current_count/float(denominator)))
            else:
                counts.append((keyword, current_count))
        counts = sorted(counts, key = lambda x: x[1], reverse = True)
        countdf = pd.DataFrame.from_records(counts, columns=["keyword", "count"]).set_index('keyword')
        #countdf = self.df["result"].value_counts()
        #countdf = countdf.head(20)
        axis = "Proportions" if proportion else "Counts"
        plot = countdf.plot(kind="bar",
                            colormap = "Reds_r",
                            title="Top 20 Keyword %s" %axis)
        plot.set_xlabel("Keywords")
        plot.set_ylabel("%s" %axis)
        plt.show()
        if fig_dir is not None:
            fig = plot.get_figure()
            fig.tight_layout()
            # save figure
            fig.savefig("%s/keyword_%s.png" % (fig_dir, axis.lower()))
        

def main():
    # First time through
    # ra = ResponseAnalyzer("./processed/responses")
    # ra.print_csv("./processed/hash_processed.csv")
    # ra = ResponseAnalyzer("./processed/hash_processed.csv", merged=True)
    # ra.get_duplicates_analysis("./processed/hash_processed_no_duplicates.csv")
    #ra.get_description("./processed/descriptions")

    # ra = ResponseAnalyzer("./processed/hash_processed_no_duplicates.csv", merged=True)
    # ra.get_keywords_df()
    # ra.print_csv("./processed/hash_processed_combined.csv")
    
    ra = ResponseAnalyzer("./processed/hash_processed_combined.csv", merged=True)
    # ra.plot_year_graph("figures")
    ra.analyze_results("./processed/descriptions")
    """for keyword in ra.KEY:
        ra.get_result_over_time(keyword, "figures/hash")"""
    ra.plot_keyword_counts("figures/hash")
    #ra.get_real_malware_analysis()
    

        
if __name__ == "__main__":
    main()

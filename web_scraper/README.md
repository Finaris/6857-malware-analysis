# Web Scraping

**!!! IMPORTANT !!!**  
Please read the following before beginning.

We will be scraping information from the URLs listed at: https://zeltser.com/malicious-ip-blocklists/

Below will be a list of URLs that we have written scrapers for, as well
as which ones remain and which are in progress. Please check in with the
group, or update the list below, before claiming a URL. 

Also, if there is a particular piece of malware which you encounter (which will be a lot),
then you should hash the malicious file associated with it (or get unique information about it).
This will allow us to detect duplicates. It's okay if you don't hash it right away when you're
scraping, but this is something we'll probably want to do manually later (i.e. make sure your 
scraper is working and deterministic before before you do this). If you don't want to manually 
hash it, you can try uploading it to: https://www.virustotal.com/#/home/upload

A quick note on this subject: before you upload it to VirusTotal you can try just googling the IP
address (please don't actually search in your URL bar or else that could be bad) and it might take
you to a source page where other information is listed and you can manually augment the record.

Lastly, the Scraper interface carefully outlines what is expected for each scraper. In 
general there's a good amount of flexibility since URLs are different, but to streamline
our data collection pipeline a few things are specified. The most important thing is a
common name and format for certain types of data. For example, when reporting a country of
origin, we require that this be stored as `origin_country` and that the value is the country's
name without any strange formatting (e.g. `"United States of America"`). We can handle edge 
cases in the aggregate scraping code and analysis. 

*If you encounter a type of data which has not
yet been documented, please update the specification of the scraper with its name and how you 
expect the data to be stored.*

URLs currently being scraped:

* http://osint.bambenekconsulting.com/feeds/
* https://github.com/esentire/malfeed
* http://security-research.dyndns.org/pub/malware-feeds/
* https://gist.github.com/bbcan177
* https://feodotracker.abuse.ch/
* http://iplists.firehol.org/ (this has a lot of data that was just kind of downloaded and overlapped with some others)
* https://www.iblocklist.com/lists
* https://www.cyberthreatalliance.org/
* https://ransomwaretracker.abuse.ch/blocklist/
* http://www.urlvir.com/
* http://vxvault.net/ViriList.php
* http://cybercrime-tracker.net/
* http://support.clean-mx.de/clean-mx/viruses
* http://www.squidblacklist.org/
* http://openphish.com/
* https://malwareconfig.com/api/
* http://www.malwaredomains.com/wordpress/?page_id=66
* http://www.phishtank.com/phish_archive.php
* http://nullsecure.org/

URLs which have been scraped (or their information extracted some other way):

* https://urlhaus.abuse.ch/browse/
* https://sslbl.abuse.ch/
* https://intel.criticalstack.com/ (I have a VM/account set up to use things here if needed)
* https://db.aa419.org/fakebankslist.php
* http://malc0de.com/database/
* https://www.malwaredomainlist.com/
* http://hosts-file.net/
* https://zeustracker.abuse.ch/blocklist.php (and https://zeustracker.abuse.ch/monitor.php?browse=binaries)


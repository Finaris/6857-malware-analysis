# -*- coding: utf-8 -*-
"""

This module implements the Scraper interface for
SSLBL for data mining purposes.

"""

import logging
import os

from datetime import datetime

from scraper import Category, RecordAttribute, Scraper


class SSLBLScraper(Scraper):
    """ Implementation of Scraper for SSLBL. """

    def __init__(self):
        # Specify the short name and move on.
        self.short_name = "sslbl"
        super().__init__(self.short_name, None, None)

        # Set and clear the remaining class attributes.
        self.base_path = os.path.dirname(os.path.realpath(__file__)) + "/persistent_data/sslbl/"
        self.files = os.listdir(self.base_path)
        self.records = {}
        self.timestamp = None

    def scrape(self):
        # Before beginning, clear all records and update the timestamp.
        self.records = {}
        self.timestamp = datetime.now()

        # Add each file as a series of records. This is a really easy CSV to pick apart.
        for i, file in enumerate(self.files):
            with open(self.base_path+file) as sslbl_file:
                records = []
                for line in sslbl_file.readlines():
                    line_content = line.strip()
                    if line_content and line_content[0] != "#":
                        date, ip, _ = line_content.split(",")
                        records.append({
                            RecordAttribute.CATEGORY: Category.BOTNET,
                            RecordAttribute.DATE: str(datetime.strptime(date, "%Y-%m-%d %H:%M:%S")),
                            RecordAttribute.IP: ip
                        })
                self.records[file] = records
            logging.info("({0}/{1}): Finished processing {2}".format(i + 1, len(self.files), file))
        logging.info("Completed scraping {0}".format(self.short_name))

# -*- coding: utf-8 -*-
"""

This module implements the Scraper interface for
hosts-file for data mining purposes.

"""

import logging
import os

from datetime import datetime

from scraper import Scraper


class HostsFileNetScraper(Scraper):
    """ Implementation of Scraper for hosts-file. """

    def __init__(self):
        # Specify the URL of malc0de and its pages we are scanning.
        self.short_name = "hosts_file_net"
        self.base_path = "persistent_data/hosts_file_net/"
        self.files = os.listdir(self.base_path)
        super().__init__(self.short_name, self.base_path, self.files)

        # Clear the remaining class attributes.
        self.records = {}
        self.timestamp = None

    def scrape(self):
        # Before beginning, clear all records, update the timestamp, and set up logging.
        self.records = {}
        self.timestamp = datetime.now()

        # Go through and store data from each file.
        for file in self.files:
            records = []
            with open(self.base_path+file, encoding='latin-1') as hosts_file:
                for line in hosts_file.readlines():
                    line_contents = line.strip().split()
                    if line_contents[0] == "127.0.0.1" and len(line_contents) == 2:
                        records.append({
                            "url": line_contents[1],
                            "category": file.split('.')[0]
                        })
            self.records[file] = records
        logging.info("Completed scraping {0}".format(self.base_path))

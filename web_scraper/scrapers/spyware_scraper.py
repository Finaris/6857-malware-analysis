# -*- coding: utf-8 -*-
"""

This module implements the Scraper interface for
spyware for data mining purposes.

"""

import logging
import os

from datetime import datetime
from ipaddress import IPv4Network

from scraper import Category, RecordAttribute, Scraper


class SpywareScraper(Scraper):
    """ Implementation of Scraper for spyware. """

    def __init__(self):
        # Specify the short name and move on.
        self.short_name = "spyware"
        super().__init__(self.short_name, None, None)

        # Set and clear the remaining class attributes.
        self.base_path = os.path.dirname(os.path.realpath(__file__)) + "/persistent_data/spyware/"
        self.files = os.listdir(self.base_path)
        self.records = {}
        self.timestamp = None

    def scrape(self):
        # Before beginning, clear all records and update the timestamp.
        self.records = {}
        self.timestamp = datetime.now()

        # Add each file as a series of records.
        for i, file in enumerate(self.files):
            with open(self.base_path+file) as spyware_file:
                records = []
                for line in spyware_file.readlines():
                    line_content = line.strip()
                    if line_content and line_content[0] != "#":
                        if self.is_url_ip_address(line_content):
                            records.append({
                                RecordAttribute.IP: line_content,
                                RecordAttribute.CATEGORY: Category.SPYWARE
                            })
                        else:
                            for ip_address in IPv4Network(line_content):
                                records.append({
                                    RecordAttribute.IP: str(ip_address),
                                    RecordAttribute.CATEGORY: Category.SPYWARE
                                })
                self.records[file] = records
            logging.info("({0}/{1}): Finished processing {2}".format(i + 1, len(self.files), file))
        logging.info("Completed scraping {0}".format(self.short_name))

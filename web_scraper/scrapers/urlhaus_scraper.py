# -*- coding: utf-8 -*-
"""

This module implements the Scraper interface for
URLHaus for data mining purposes.

"""

import logging
import os

from datetime import datetime
from typing import Dict, List

from scraper import Category, RecordAttribute, Scraper


class URLHausScraper(Scraper):
    """ Implementation of Scraper for URLHaus. """

    def __init__(self):
        # Specify the short name and move on.
        self.short_name = "urlhaus"
        super().__init__(self.short_name, None, None)

        # Set and clear the remaining class attributes.
        self.base_path = os.path.dirname(os.path.realpath(__file__)) + "/persistent_data/urlhaus/"
        self.files = os.listdir(self.base_path)
        self.records = {}
        self.timestamp = None

    def scrape(self):
        # Before beginning, clear all records and update the timestamp.
        self.records = {}
        self.timestamp = datetime.now()

        # Process abuse files first.
        self.records[self.files[0]] = self._process_abuse(self.files[0])
        logging.info("(1/{0}): Finished processing {1}".format(len(self.files), self.files[0]))

        # Process payloads second.
        for i, file_name in enumerate(self.files[1:]):
            self.records[file_name] = self._process_payloads(file_name)
            logging.info("({0}/{1}): Finished processing {2}".format(i+2, len(self.files), file_name))

        logging.info("Completed scraping {0}".format(self.short_name))

    def _process_abuse(self, file_name: str) -> List[Dict]:
        """ Given a URLHaus abuse file, convert it into our representation.

        :param file_name: (str) Name of the file containing abuse data.
        :return: (list) A list of records.
        """
        with open(self.base_path+file_name) as abuse_file:
            records = []
            for line in abuse_file.readlines():
                # Ignore comments at the beginning of the file.
                if line[0] == "#":
                    continue

                # Break apart the CSV and make a record.
                _, date, url, status, _, _, _ = line.strip().split("\",\"")
                records.append({
                    RecordAttribute.DATE: str(datetime.strptime(date, "%Y-%m-%d %H:%M:%S")),
                    RecordAttribute.URL: url,
                    RecordAttribute.STATUS: status,
                    RecordAttribute.CATEGORY: Category.GENERAL_MALWARE
                })
            return records

    def _process_payloads(self, file_name: str) -> List[Dict]:
        """ Given a URLHaus payload file, convert it into our representation.

        :param file_name: (str) Name of the file containing payload data.
        :return: (list) A list of records.
        """
        with open(self.base_path + file_name) as payload_file:
            records = []
            for line in payload_file.readlines():
                # Ignore comments at the beginning of the file.
                if line[0] == "#":
                    continue

                # Break apart the CSV and make a record.
                date, url, filetype, md5, _, _ = line.strip().split("\",\"")
                records.append({
                    RecordAttribute.DATE: str(datetime.strptime(date, "\"%Y-%m-%d %H:%M:%S")),
                    RecordAttribute.URL: url,
                    RecordAttribute.FILETYPE: filetype,
                    RecordAttribute.MD5: md5,
                    RecordAttribute.CATEGORY: Category.GENERAL_MALWARE
                })
            return records
